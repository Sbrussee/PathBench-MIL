experiment:
  project_name: Exp1 # Name of the project
  annotation_file: /path/to/your/annotations # Path to the annotation file
  balancing: event # Balancing can be 'tile', 'slide', 'patient' or 'category'
  class_weighting: False # Whether to use class weighting for imbalanced datasets  
  split_technique: k-fold # Split technique can be 'k-fold' or 'fixed' or 'k_fold_site_preserved'
  k: 3 # Number of folds for k-fold cross-validation
  val_fraction: 0.1 # Fraction of the training data to be used for validation
  best_epoch_based_on: val_loss # Metric to be used for selecting the best epoch, can be val_loss or any metric in evaluation
  epochs: 25 # Number of epochs for training
  batch_size: 32 # Batch size for training
  bag_size: 512 # Bag size for MIL models
  encoder_layers: 1 # Number of layers in the MIL encoder
  z_dim: 256 # Dimension of the latent space in the MIL encoder
  dropout_p: 0.25 # Dropout probability for the MIL model
  num_workers: 0 # Number of workers for data loading, 0 for no parallelization.
  aggregation_level: patient # Aggregation level can be 'slide' or 'patient'
  task: survival_discrete # Task can be 'classification', 'regression' or 'survival' or 'survival_discrete'
  mode: benchmark # Mode can be either 'benchmark' or 'optimization'.
  custom_metrics: [RocAuc] # Custom metrics to be used, needs to be defined in metrics.py or as a fastai-metric: https://docs.fast.ai/metrics.html
  report: False # Whether to generate a tile extraction report
  feature_extraction_only: False
  
  qc: # List of quality control methods to be used
    - GaussianV2
    - Otsu-CLAHE

  qc_filters: #Tile-level filters for discarding tiles
    grayspace_threshold : 0.05 #Pixels below this value (ranged 0-1) are considered gray.
    grayspace_fraction: 0.6 # Image tiles with grayspace above this fraction are discarded.
    whitespace_threshold: 230 #Pixel intensities (0-255) above this value are considered white.
    whitespace_fraction: 1.0 # Image tiles with whitespace above this fraction are discarded.

  evaluation:
    - c_index
    - brier_score

  visualization:
    - concordance_index
    - kaplan_meier
    - survival_roc


datasets: # List of datasets to be used
  - name: training1 # Name of the dataset
    slide_path: path/to/your/slides # Path to the slide data
    tfrecord_path: path/to/your/tfrecords # Path to save tfrecords
    tile_path: path/to/save/tiles # Path to save tiles
    used_for: training # Whether the dataset is used for training or testing

  - name: testing1
    slide_path: path/to/your/slides
    tfrecord_path: path/to/your/tfrecords
    tile_path: path/to/save/tiles
    used_for: testing

benchmark_parameters:
  tile_px: # Tile sizes in pixels
    - 256 
  tile_um: # Magnifications (e.g. 40x, 20x, 10x)
    - 20x
  normalization: # Normalization methods, can be 'macenko', 'reinhard' or 'cyclegan'
    - macenko

  feature_extraction: # Feature extraction methods, as specified in feature_extractors.py
    - h_optimus_0
    - virchow2
    - uni
    - resnet50_imagenet

  mil: # MIL models, as specified in aggregators.py
    - clam_mil
    - dsmil
    - varmil
    - attention_mil

  loss: # Loss functions, as specified in losses.py
    - CrossEntropyLoss

  activation_function: # activation function for the MIL encoder, supports any pytorch.nn activation function.
    - ReLU

  optimizer: # Optimizers, can be any fastai optimizer (Default: Adam)
    - Adam
  
weights_dir: ./pretrained_weights # Path to pretrained weights and/or where to save retrieved weights, defaults to the pretrained_weights directory in the PathDev repository
hf_key: YOUR_HUGGINGFACE_TOKEN # Token for Hugging Face model hub to access gated models, if you do not have one, just set to None